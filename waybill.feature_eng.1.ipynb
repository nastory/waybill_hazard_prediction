{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering 1\n",
    "\n",
    "This will be our first interation of feature engineering. During our EDA, we were able to do the feature selection, so now all that's left is to prepare the data with encoding and scaling. We'll also be developing out \"route sentences,\" which will be the text representation of our train routes.\n",
    "\n",
    "We'll start by reading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plaidml.keras as pk\n",
    "pk.install_backend()\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_hazardous</th>\n",
       "      <th>car_ownership_category_code</th>\n",
       "      <th>all_rail_intermodal_code</th>\n",
       "      <th>estimated_short_line_miles</th>\n",
       "      <th>number_of_articulated_units</th>\n",
       "      <th>origin_location</th>\n",
       "      <th>interchange_state_1</th>\n",
       "      <th>interchange_state_2</th>\n",
       "      <th>interchange_state_3</th>\n",
       "      <th>terminal_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>2120</td>\n",
       "      <td>0</td>\n",
       "      <td>Chicago-Gary-Kenosha, IL-IN-WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles-Riverside-Orange County, CA-AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>9</td>\n",
       "      <td>810</td>\n",
       "      <td>0</td>\n",
       "      <td>Chicago-Gary-Kenosha, IL-IN-WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philadelphia-Wilmington-Atlantic City, PA-NJ-D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>New Orleans, LA-MS</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>9</td>\n",
       "      <td>2470</td>\n",
       "      <td>4</td>\n",
       "      <td>Baton Rouge, LA-MS</td>\n",
       "      <td>IL</td>\n",
       "      <td>AB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alberta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>Chicago-Gary-Kenosha, IL-IN-WI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shreveport-Bossier City, LA-AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_hazardous car_ownership_category_code  all_rail_intermodal_code  \\\n",
       "0             1                           P                         1   \n",
       "1             1                           P                         9   \n",
       "2             1                           P                         1   \n",
       "3             1                           P                         9   \n",
       "4             1                           P                         1   \n",
       "\n",
       "   estimated_short_line_miles  number_of_articulated_units  \\\n",
       "0                        2120                            0   \n",
       "1                         810                            0   \n",
       "2                         350                            0   \n",
       "3                        2470                            4   \n",
       "4                         860                            0   \n",
       "\n",
       "                  origin_location interchange_state_1 interchange_state_2  \\\n",
       "0  Chicago-Gary-Kenosha, IL-IN-WI                 NaN                 NaN   \n",
       "1  Chicago-Gary-Kenosha, IL-IN-WI                 NaN                 NaN   \n",
       "2              New Orleans, LA-MS                  AL                 NaN   \n",
       "3              Baton Rouge, LA-MS                  IL                  AB   \n",
       "4  Chicago-Gary-Kenosha, IL-IN-WI                 NaN                 NaN   \n",
       "\n",
       "  interchange_state_3                                  terminal_location  \n",
       "0                 NaN         Los Angeles-Riverside-Orange County, CA-AZ  \n",
       "1                 NaN  Philadelphia-Wilmington-Atlantic City, PA-NJ-D...  \n",
       "2                 NaN                                     Birmingham, AL  \n",
       "3                 NaN                                            Alberta  \n",
       "4                 NaN                     Shreveport-Bossier City, LA-AR  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./waybill_relevant_data.csv', low_memory=False)\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to try using some NLP techniques on the train route, since right now the routes are stored as sequences of string data. So let's engineer the features in the same ways we would engineer sentences, for example.\n",
    "\n",
    "In this way our predictions become comparable to a simple case of sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_cols = [\n",
    "    'origin_location',\n",
    "    'interchange_state_1',\n",
    "    'interchange_state_2',\n",
    "    'interchange_state_3',\n",
    "    'terminal_location'\n",
    "]\n",
    "\n",
    "\n",
    "def to_sentence(row):\n",
    "    ls = []\n",
    "    for c in seq_cols:\n",
    "        if (row[c] is None) or (row[c] is np.nan):\n",
    "            continue\n",
    "            \n",
    "        ls.append(row[c].replace(', ', '').replace(' ', '').replace('-', ''))\n",
    "        \n",
    "    return ' '.join(ls)\n",
    "\n",
    "    \n",
    "routes = df.apply(to_sentence, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChicagoGaryKenoshaILINWI LosAngelesRiversideOrangeCountyCAAZ',\n",
       " 'ChicagoGaryKenoshaILINWI PhiladelphiaWilmingtonAtlanticCityPANJDEMD',\n",
       " 'NewOrleansLAMS AL BirminghamAL',\n",
       " 'BatonRougeLAMS IL AB Alberta',\n",
       " 'ChicagoGaryKenoshaILINWI ShreveportBossierCityLAAR',\n",
       " 'CasperWYIDUT TX BeaumontPortArthurTX',\n",
       " 'NewOrleansLAMS BeaumontPortArthurTX',\n",
       " 'LosAngelesRiversideOrangeCountyCAAZ LosAngelesRiversideOrangeCountyCAAZ',\n",
       " 'NewOrleansLAMS BeaumontPortArthurTX',\n",
       " 'HoustonGalvestonBrazoriaTX TX TX Mexico']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our \"route sentences\" we need to know the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": [
    "long_str = ' '.join(routes)\n",
    "\n",
    "long_ls = long_str.split()\n",
    "vocab_set = set()\n",
    "for l in long_ls:\n",
    "    vocab_set.add(l)\n",
    "    \n",
    "print(len(vocab_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 212 distinct words in our vocab, so we'll choose a vocab size of 300, allowing for some unseen values. The maximum route length is five stops, so our max sentence length will be 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 300\n",
    "max_length = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply our encoding and padding, and then dump the numpy arrays of our prepared data and the encoder to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[162, 174], [162, 201], [196, 7, 187], [208, 233, 236, 200], [162, 268]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_routes = [one_hot(r, vocab_size) for r in routes]\n",
    "encoded_routes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./one_hot_encoder.pickle', 'wb') as f:\n",
    "    pickle.dump(one_hot, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162, 174,   0,   0,   0],\n",
       "       [162, 201,   0,   0,   0],\n",
       "       [196,   7, 187,   0,   0],\n",
       "       [208, 233, 236, 200,   0],\n",
       "       [162, 268,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_routes = pad_sequences(encoded_routes, maxlen=max_length, padding='post')\n",
    "padded_routes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = padded_routes\n",
    "y = df['is_hazardous'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = (X_seq, y)\n",
    "\n",
    "with open('sequence_data.pickle', 'wb') as f:\n",
    "    pickle.dump(seq_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For numerical and category data\n",
    "\n",
    "For our traditional numerical and category data, we'll be applying one-hot encoding and min max scaling, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'estimated_short_line_miles',\n",
    "    'number_of_articulated_units'\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    'car_ownership_category_code', \n",
    "    'all_rail_intermodal_code'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = df[num_cols]\n",
    "cats = df[cat_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ownership_category_code_P</th>\n",
       "      <th>car_ownership_category_code_R</th>\n",
       "      <th>car_ownership_category_code_T</th>\n",
       "      <th>all_rail_intermodal_code_1</th>\n",
       "      <th>all_rail_intermodal_code_2</th>\n",
       "      <th>all_rail_intermodal_code_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_ownership_category_code_P  car_ownership_category_code_R  \\\n",
       "0                              1                              0   \n",
       "1                              1                              0   \n",
       "2                              1                              0   \n",
       "3                              1                              0   \n",
       "4                              1                              0   \n",
       "\n",
       "   car_ownership_category_code_T  all_rail_intermodal_code_1  \\\n",
       "0                              0                           1   \n",
       "1                              0                           0   \n",
       "2                              0                           1   \n",
       "3                              0                           0   \n",
       "4                              0                           1   \n",
       "\n",
       "   all_rail_intermodal_code_2  all_rail_intermodal_code_9  \n",
       "0                           0                           0  \n",
       "1                           0                           1  \n",
       "2                           0                           0  \n",
       "3                           0                           1  \n",
       "4                           0                           0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all_rail_intermodal_code'] = df['all_rail_intermodal_code'].astype(str)\n",
    "encoded_cats = pd.get_dummies(cats)\n",
    "encoded_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cats = encoded_cats.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38061041, 0.        ],\n",
       "       [0.1454219 , 0.        ],\n",
       "       [0.06283662, 0.        ],\n",
       "       [0.44344704, 0.8       ],\n",
       "       [0.15439856, 0.        ],\n",
       "       [0.27648115, 0.        ],\n",
       "       [0.04847397, 0.        ],\n",
       "       [0.01256732, 0.        ],\n",
       "       [0.04847397, 0.        ],\n",
       "       [0.11849192, 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_nums = scaler.fit_transform(nums)\n",
    "\n",
    "X_nums[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is scaled and encoded, we will pickle the scaler and the numerical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./min_max_scaler.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68486, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate([X_nums, X_cats], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68486, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = (X, y)\n",
    "\n",
    "with open('./numerical_data.pickle', 'wb') as f:\n",
    "    pickle.dump(num_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to send our data to model training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
