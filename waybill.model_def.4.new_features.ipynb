{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition 4\n",
    "\n",
    "Now that we've one-hot encoded the route data, there is no need for the hybrid model, so we'll use a simple 1D CNN instead.\n",
    "\n",
    "Let's see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import plaidml.keras as pk\n",
    "pk.install_backend()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv1D, Dropout, LeakyReLU, MaxPooling1D, Embedding, Flatten, Input, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./big_dummy_data.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68486, 420)\n",
      "(68486,)\n"
     ]
    }
   ],
   "source": [
    "X, y = dataset\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.33)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLearning Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    inp = Input(shape=(420,1))\n",
    "    \n",
    "    x = Conv1D(1024, kernel_size=4, strides=1)(inp)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPooling1D(pool_size=4)(x)\n",
    "    \n",
    "    x = Conv1D(512, kernel_size=4, strides=1)(inp)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPooling1D(pool_size=4)(x)\n",
    "    \n",
    "    x = Conv1D(64, kernel_size=4, strides=1)(inp)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPooling1D(pool_size=4)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    \n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                 metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction_combined = ReduceLROnPlateau(monitor='val_acc', patience=3, \n",
    "                                            verbose=2, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "best_model_combined = ModelCheckpoint('./simple_cnn.1.h5', monitor='val_acc', verbose=2, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping_combined = EarlyStopping(monitor='val_loss', min_delta=1e-10, \n",
    "                               patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45885 samples, validate on 22601 samples\n",
      "Epoch 1/50\n",
      "45885/45885 [==============================] - 12s 270us/step - loss: 0.3188 - acc: 0.8758 - val_loss: 0.2817 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89580, saving model to ./simple_cnn.1.h5\n",
      "Epoch 2/50\n",
      "45885/45885 [==============================] - 10s 219us/step - loss: 0.2610 - acc: 0.9060 - val_loss: 0.2620 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89580 to 0.90739, saving model to ./simple_cnn.1.h5\n",
      "Epoch 3/50\n",
      "45885/45885 [==============================] - 10s 218us/step - loss: 0.2433 - acc: 0.9131 - val_loss: 0.2484 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.90739 to 0.91230, saving model to ./simple_cnn.1.h5\n",
      "Epoch 4/50\n",
      "45885/45885 [==============================] - 10s 218us/step - loss: 0.2325 - acc: 0.9170 - val_loss: 0.2383 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91230 to 0.91571, saving model to ./simple_cnn.1.h5\n",
      "Epoch 5/50\n",
      "45885/45885 [==============================] - 10s 218us/step - loss: 0.2248 - acc: 0.9200 - val_loss: 0.2421 - val_acc: 0.9150\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91571\n",
      "Epoch 6/50\n",
      "45885/45885 [==============================] - 10s 219us/step - loss: 0.2204 - acc: 0.9214 - val_loss: 0.2435 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91571\n",
      "Epoch 7/50\n",
      "45885/45885 [==============================] - 10s 215us/step - loss: 0.2152 - acc: 0.9232 - val_loss: 0.2359 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91571 to 0.91629, saving model to ./simple_cnn.1.h5\n",
      "Epoch 8/50\n",
      "45885/45885 [==============================] - 10s 221us/step - loss: 0.2116 - acc: 0.9249 - val_loss: 0.2344 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91629\n",
      "Epoch 9/50\n",
      "45885/45885 [==============================] - 10s 220us/step - loss: 0.2092 - acc: 0.9252 - val_loss: 0.2412 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91629 to 0.91713, saving model to ./simple_cnn.1.h5\n",
      "Epoch 10/50\n",
      "45885/45885 [==============================] - 10s 222us/step - loss: 0.2062 - acc: 0.9265 - val_loss: 0.2336 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.91713 to 0.91930, saving model to ./simple_cnn.1.h5\n",
      "Epoch 11/50\n",
      "45885/45885 [==============================] - 10s 221us/step - loss: 0.2042 - acc: 0.9265 - val_loss: 0.2369 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91930\n",
      "Epoch 12/50\n",
      "45885/45885 [==============================] - 10s 212us/step - loss: 0.2027 - acc: 0.9268 - val_loss: 0.2305 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.91930 to 0.92040, saving model to ./simple_cnn.1.h5\n",
      "Epoch 13/50\n",
      "45885/45885 [==============================] - 10s 222us/step - loss: 0.2006 - acc: 0.9283 - val_loss: 0.2314 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92040 to 0.92080, saving model to ./simple_cnn.1.h5\n",
      "Epoch 14/50\n",
      "45885/45885 [==============================] - 10s 221us/step - loss: 0.1990 - acc: 0.9283 - val_loss: 0.2357 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92080\n",
      "Epoch 15/50\n",
      "45885/45885 [==============================] - 10s 219us/step - loss: 0.1985 - acc: 0.9281 - val_loss: 0.2295 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.92080 to 0.92138, saving model to ./simple_cnn.1.h5\n",
      "Epoch 16/50\n",
      "45885/45885 [==============================] - 10s 223us/step - loss: 0.1969 - acc: 0.9293 - val_loss: 0.2400 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92138\n",
      "Epoch 17/50\n",
      "45885/45885 [==============================] - 10s 220us/step - loss: 0.1964 - acc: 0.9294 - val_loss: 0.2317 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92138\n",
      "Epoch 18/50\n",
      "45885/45885 [==============================] - 10s 221us/step - loss: 0.1959 - acc: 0.9290 - val_loss: 0.2331 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.92138 to 0.92155, saving model to ./simple_cnn.1.h5\n",
      "Epoch 19/50\n",
      "45885/45885 [==============================] - 10s 221us/step - loss: 0.1945 - acc: 0.9300 - val_loss: 0.2359 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.92155 to 0.92199, saving model to ./simple_cnn.1.h5\n",
      "Epoch 20/50\n",
      "45885/45885 [==============================] - 10s 220us/step - loss: 0.1937 - acc: 0.9303 - val_loss: 0.2355 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92199\n",
      "Epoch 21/50\n",
      "45885/45885 [==============================] - 10s 220us/step - loss: 0.1927 - acc: 0.9302 - val_loss: 0.2331 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92199\n",
      "Epoch 22/50\n",
      "45885/45885 [==============================] - 10s 219us/step - loss: 0.1927 - acc: 0.9297 - val_loss: 0.2415 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92199\n",
      "Epoch 23/50\n",
      "45885/45885 [==============================] - 10s 219us/step - loss: 0.1866 - acc: 0.9315 - val_loss: 0.2362 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.92199 to 0.92235, saving model to ./simple_cnn.1.h5\n",
      "Epoch 24/50\n",
      "45885/45885 [==============================] - 10s 220us/step - loss: 0.1850 - acc: 0.9324 - val_loss: 0.2379 - val_acc: 0.9226\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.92235 to 0.92257, saving model to ./simple_cnn.1.h5\n",
      "Epoch 25/50\n",
      "45885/45885 [==============================] - 10s 220us/step - loss: 0.1850 - acc: 0.9320 - val_loss: 0.2414 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.92257\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "         batch_size=32,\n",
    "         epochs=50,\n",
    "         validation_data=(x_test, y_test),\n",
    "         callbacks = [learning_rate_reduction_combined, best_model_combined, early_stopping_combined],\n",
    "         verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our best model yet, scoring 92.2% accuracy (v. the previous high of 91.7%). This is a fine example of how sometimes bigger doesn't mean better.\n",
    "\n",
    "Let's evaluate our models in the model_evaluate.4 notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
